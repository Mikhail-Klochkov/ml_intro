{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Recsystem_HW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mikhail-Klochkov/ml_intro/blob/master/Recsystem_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtYHU4IYXkUL"
      },
      "source": [
        "# Домашнее задание по рекомендательным системам"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kex3O5hHXkUR"
      },
      "source": [
        "В данном домашнем задании вам предлагается реализовать User-based рекомендательную систему. Так же требуется реализовать несколько вспомогательных функций, шаблоны которых вы можете найти в `utils.py`.\n",
        "\n",
        "Требования к выполнению задания:\n",
        "- Реализация функции из `utils.py` засчитывается, только если пройдены все соответствующие тесты из `test.py`. Запуск тестов: <font color='red'>pytest test.py</font>. Для тестов вам потребуются библиотеки `numpy`, `scipy`, `pytest` и `hypothesis`.\n",
        "- Плагиат запрещен. Если будет замечено, что часть задания списана, то 0 баллов ставится как списывающему, так и давшему списать.\n",
        "- Если пользуетесь кодом из открытых источников, то указывайте ссылки, откуда взяли решение. Иначе такой код может быть воспринят как плагиат.\n",
        "- При выполнении задания нельзя использовать библиотеку `scipy` и функцию `numpy.linalg.norm`\n",
        "\n",
        "При запуске тестов могут появиться предупреждения: PearsonRConstantInputWarning и PearsonRNearConstantInputWarning. На них можно не обращать внимания.\n",
        "\n",
        "Возможный максимум баллов за задание: 10 баллов <br>\n",
        "Дедлайн: ??? <br>\n",
        "Штраф: ??? - будет ли в курсе штраф? <br>\n",
        "<br>\n",
        "Для ускорения проверки, напишите здесь получившееся количество баллов: (Не знаю, но тесты все прошёл файлик utils.py and test.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tnWPvFcXkUS"
      },
      "source": [
        "## 1. Метрика сходства\n",
        "<b>1.1. Реализация метрик (2 балла)</b>\n",
        "\n",
        "Первое, с чем необходимо разобраться, при реализации User-based подхода, это с метрикой, с помощью которой будет решаться, насколько похожи пользователи. Вам предлагается реализовать 2 метрики: на основе евклидовой метрики и коэффициент корреляции Пирсона. Шаблоны для обоих функций можете найти в `utils.py`. Не забудьте проверить реализацию на тестах.\n",
        "\n",
        "Евклидова метрика:\n",
        "\\begin{equation}\n",
        "d(p,q)=\\sqrt{(p_1-q_1)^2+(p_2-q_2)^2+\\dots+(p_n-q_n)^2} = \\sqrt{\\sum_{k=1}^n (p_k-q_k)^2}\n",
        "\\end{equation}\n",
        "\n",
        "В этом случае $d(p, q) \\in [0, \\infty)$, при этом если $d(p, q) \\to 0$, то $sim(p, q) \\to 1$. С учетом этого конечная формула будет выглядеть следующим образом:\n",
        "\\begin{equation}\n",
        "sim(p, q) = \\frac{1}{1 + d(p, q)}\n",
        "\\end{equation}\n",
        "Так же в этой формуле не будет проблем с делением на 0.\n",
        "\n",
        "Коэффициент корреляции Пирсона:\n",
        "\\begin{equation}\n",
        "r_{xy} = \\frac {\\sum_{i=1}^{m} \\left( x_i-\\bar{x} \\right)\\left( y_i-\\bar{y} \\right)}{\\sqrt{\\sum_{i=1}^{m} \\left( x_i-\\bar{x} \\right)^2 \\sum_{i=1}^{m} \\left( y_i-\\bar{y} \\right)^2}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ8Cta5aXkUS"
      },
      "source": [
        "<b>1.2. (1 балл)</b>\n",
        "\n",
        "Рассмотрим пользователей $u$ и $v$. Им соотвествуют векторы $x_u$ и $x_v$, где $x_u[i] = r_{ui}$ и $x_v[i] = r_{vi}$. Из лекции известно, что похожесть между векторами $x_u$ и $x_v$ вычисляются только для тех индексов i, для которых существует и $r_{ui}$, и $r_{vi}$. То есть верно следуюющее:\n",
        "\\begin{equation}\n",
        "sim(u, v) = sim(x_uI_{uv}, x_vI_{uv}),\n",
        "\\end{equation}\n",
        "где $I_{uv} = [i | \\exists r_{ui} \\& \\exists r_{vi}]$. При этом если $I_{uv} = \\emptyset$, то $sim(u, v) \\to -\\infty$.\n",
        "\n",
        "Реализуйте два новых метода, которые переиспользуют написанные вами `euclidean_distance` и `pearson_distance`, добавляющие условия на $x_u$ и $x_v$. Считается, что $x_u[i] = 0$, если $\\nexists r_{ui}$. То же верно для $x_v$.\n",
        "\n",
        "При реализации заданий можно как написать новые функции, так и использовать декораторы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP8HX3XUaRa8",
        "outputId": "80c23af6-71db-4fb7-db07-8d4fcdcf51e3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnvJbAjzXkUT"
      },
      "source": [
        "import numpy as np\n",
        "import drive.MyDrive.Colab_Notebooks.recomendation_system.utils as utils\n",
        "from drive.MyDrive.Colab_Notebooks.recomendation_system.utils import euclidean_similarity, euclidean_distance, pearson_similarity\n",
        "\n",
        "\n",
        "def disteuclid(x, y):\n",
        "  return np.sqrt(((x - y) ** 2).sum())\n",
        "\n",
        "def simeuclid(x, y):\n",
        "  return 1 / ( 1 + disteuclid(x, y))\n",
        "\n",
        "def euclidean_similarity2_colab(x: np.ndarray, y: np.ndarray) -> float:\n",
        "    mask = ((x != 0) & (y != 0))\n",
        "    x_not_zero = x[mask]\n",
        "    y_not_zero = y[mask]\n",
        "    # -- not exist intersection -- #\n",
        "    return simeuclid(x_not_zero, y_not_zero) if x_not_zero.shape[0] != 0 else -np.inf\n",
        "\n",
        "def pearson_similarity2_colab(x: np.ndarray, y : np.ndarray ) -> float:\n",
        "    mask = ((x != 0) & (y != 0))\n",
        "    x_not_zero = x[mask]\n",
        "    y_not_zero = y[mask]\n",
        "    # -- not exist intersection -- #\n",
        "    return pearson_similarity(x_not_zero, y_not_zero) if x_not_zero.shape[0] != 0 else -np.inf\n",
        "\n",
        "def PS_colab(x: np.ndarray, y : np.ndarray ) -> float:\n",
        "    mask = ((x != 0) & (y != 0))\n",
        "    x_not_zero = x[mask]\n",
        "    y_not_zero = y[mask]\n",
        "    # -- not exist intersection -- #\n",
        "    dx = x_not_zero - x.mean()\n",
        "    dy = y_not_zero - y.mean()\n",
        "    return np.dot(dx, dy)/(np.linalg.norm(dx) * np.linalg.norm(dy)) if x_not_zero.shape[0] > 1 else -np.inf\n",
        "\n",
        "def PSweighted_colab(x: np.ndarray, y : np.ndarray ) -> float:\n",
        "  maskint = ((x != 0) & (y != 0))\n",
        "  maskun = ((x != 0) | (y != 0))\n",
        "  x_not_zero = x[maskint]\n",
        "  y_not_zero = y[maskint]\n",
        "  dx = x_not_zero - x.mean()\n",
        "  dy = y_not_zero - y.mean()\n",
        "  weight = maskint.sum()/maskun.sum()\n",
        "  return weight * np.dot(dx, dy)/(np.linalg.norm(dx) * np.linalg.norm(dy)) if x_not_zero.shape[0] > 1 else -np.inf\n",
        "  \n",
        "def Eweighted_colab(x: np.ndarray, y: np.ndarray) -> float:\n",
        "    maskint = ((x != 0) & (y != 0))\n",
        "    maskun = ((x != 0) | (y != 0))\n",
        "    x_not_zero = x[maskint]\n",
        "    y_not_zero = y[maskint]\n",
        "    # -- not exist intersection -- #\n",
        "    weight = maskint.sum()/maskun.sum()\n",
        "    return weight * euclidean_similarity(x_not_zero, y_not_zero) if len(x_not_zero) != 0 else -np.inf \n",
        "\n"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5ZSNScIcg4L",
        "outputId": "520b95f1-28c5-48fc-c7ff-8edd9f94c0b5"
      },
      "source": [
        "! wget \"https://www.kaggle.com/rounakbanik/the-movies-dataset#ratings_small.csv\" \n"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-12 22:50:32--  https://www.kaggle.com/rounakbanik/the-movies-dataset\n",
            "Resolving www.kaggle.com (www.kaggle.com)... 35.244.233.98\n",
            "Connecting to www.kaggle.com (www.kaggle.com)|35.244.233.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘the-movies-dataset.1’\n",
            "\n",
            "the-movies-dataset.     [  <=>               ]  62.91K   152KB/s    in 0.4s    \n",
            "\n",
            "2021-05-12 22:50:34 (152 KB/s) - ‘the-movies-dataset.1’ saved [64416]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a01uSEEaXkUU"
      },
      "source": [
        "## 2. User-based method\n",
        "<b>2.1. (3 балла)</b> \n",
        "\n",
        "Реализовать User-based подход, реализовав методы класса `UserBasedRecommendation`, основанного на использовании `NearestNeighbors`. В качестве метрики может для нахождения похожих пользователей может быть использована как евклидова метрика, так и коэффициент корреляции Пирсона.\n",
        "\n",
        "Не забывайте, что `NearestNeighbors` ищет минимум расстояния между элементами, поэтому логично в качестве метрики при инициализации `NearestNeighbors` использовать обратную метрике схожести. То есть такую, что когда $sim(u, v) \\to 1$, то $d(u, v) \\to 0$. Например: $d(u, v) = 1 - sim(u, v)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt2AqO4EXkUU"
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "from typing import Optional\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "class UserBasedRecommendation:\n",
        "    def __init__(self, \n",
        "                 metric: str = 'euclidean', \n",
        "                 n_recommendations: int = 5, \n",
        "                 alpha: float = 0.8,\n",
        "                 verbose = 0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            metric: name of metric: ['euclidean', 'pearson']\n",
        "            n_recommendations: number of recommendations. Also can be specified self.make_recommendation\n",
        "            alpha: similarity threshold: if sim(u, v) > alpha then u and v are similar\n",
        "        \"\"\"\n",
        "        self._metric = metric\n",
        "        self._n_recomendations = n_recommendations\n",
        "        self._alpha = alpha \n",
        "        self._verbose = verbose\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            X: matrix N x M where X[u, i] = r_{ui} if r_{ui} exists else X[u, i] = 0\n",
        "        \"\"\"\n",
        "        # -- sparse matrix -- #\n",
        "        if(not isinstance(X, np.ndarray)):\n",
        "          self.X_ = np.copy(X.todense())\n",
        "        else:\n",
        "          self._X = np.copy(X)\n",
        "\n",
        "        print(\"shape X matrix: {}\".format(self._X.shape))\n",
        "\n",
        "    def find_closest_users(self, \n",
        "                             user_id: int, \n",
        "                             n_closest_users: int):\n",
        "      \n",
        "        \"\"\"\n",
        "        user_id - it's index in array self._X\n",
        "        n_closest_users - it's number of closest users to user_id\n",
        "        return: dists and closest indeces users\n",
        "        \"\"\"\n",
        "        # -- Что подавать оригинальный или нет user_id -- #\n",
        "        # -- Количество n_closest_users -- #\n",
        "        # -- d = 1 - sim(u, v) -- #\n",
        "        # -- по идее в группу схожих объектов надо убрать его самого, а то мы можем таким образом посоветовать, что уже пользователь смотрел -- #\n",
        "        \n",
        "        assert(isinstance(self._X, np.ndarray))\n",
        "        x0 = self._X[user_id].reshape(1, self._X.shape[1])\n",
        "        assert(x0.shape.__len__() == 2)\n",
        "        # -- + 1 сделать поправку на пользователя, которые представляет самого себя в массиве данных -- #\n",
        "        NB = NearestNeighbors(n_neighbors = n_closest_users + 1, \n",
        "                         metric = sim2metrics(Eweighted) \n",
        "                                  if self._metric == 'euclidean' else \n",
        "                                  sim2metrics(PSweighted))\n",
        "        NB.fit(self._X)\n",
        "        # -- get distances metric(x1, x2) and indeces closest users with x0 element -- #        \n",
        "        dists, indeces = NB.kneighbors(x0)\n",
        "        # -- [1:] - не выводит самого себя среди списка -- #\n",
        "        return dists[0][1: ], indeces[0][1:]\n",
        "\n",
        "# -- Optional need for x : int  = None without errors -- #\n",
        "    def make_recommendation(self, \n",
        "                            user_id: int, \n",
        "                            n_recommendations: Optional[int] = None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            user_id: user id to whom you want to recommend\n",
        "            n_recommendations: number of recommendations\n",
        "        \"\"\"\n",
        "        # -- Немного не ясно зачем f_closest принимает количество ближайших, если у нас есть параметр alpha, который позволяет -- # \n",
        "        # -- Определить окрестность (соседей), которые ближайшие к данному user_id -- #\n",
        "        dists, indeces = self.find_closest_users(user_id, self._X.shape[0]-1)\n",
        "        # -- sim(p, q) = 1 - d(p, q)\n",
        "        neighbors_idxs = indeces[((1 - dists) > self._alpha)]\n",
        "        if(self._verbose > 0):\n",
        "          print('userID: {} number of neighbors: {}'.format(user_id, ((1 - dists) > self._alpha).sum()))\n",
        "\n",
        "        # -- Из этого же множества объектов для каждого фильма, должны посмотреть p_i -- #\n",
        "        # -- Все при условии, что матрица будет типа np.ndarray -- #\n",
        "        P = np.array([\n",
        "              (self._X[neighbors_idxs, item_idx] != 0).sum()/len(neighbors_idxs)\n",
        "              for item_idx in range(self._X.shape[1])\n",
        "            ])\n",
        "        if(self._verbose > 0):\n",
        "          print('p sizes: {}'.format(P.shape[0]))\n",
        "        # -- sort and get top n_recomendations -- #\n",
        "        # -- Зачем нам в параметрах класса иметь n_recomendations и передавать данный аргумент в функцию аттрибута класса, они что, разные? -- #\n",
        "        topidxitems = P.argsort()[::-1][:n_recommendations]\n",
        "        # -- Вернутся преобразованные индексы -- #\n",
        "        # -- Потом словарём надо их переименовать обратно -- #\n",
        "        return topidxitems\n",
        "        \n",
        "\n",
        "        "
      ],
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndMbt6kXnR_c"
      },
      "source": [
        "Ниже я делаю некоторую обёртку, которая по переданной функции similarities возвращает метрику $1-sim(p,q) = d(p, q)$. А также обычная функция, корая по переданному корпусу данных, одного объекта и переданной метрики, возвращает к ближайших соседей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtkpFjpwaFYa"
      },
      "source": [
        "def sim2metrics(sim):\n",
        "  \"\"\"\n",
        "  wrapper\n",
        "  x, y - np.ndarray 1-d\n",
        "  get similarity function sim(x, y)\n",
        "  \"\"\"\n",
        "  def metric(x, y):\n",
        "    \"\"\"\n",
        "    x, y - is np.ndarray\n",
        "    \"\"\"\n",
        "    return 1 - sim(x, y)\n",
        "  return metric\n",
        "\n",
        "def getkNearestNeighbors(X: np.ndarray, \n",
        "                         x: np.ndarray,\n",
        "                         metric,  \n",
        "                         k : int = 5,\n",
        "                         metric_params = {}):\n",
        "  \"\"\"\n",
        "  get X array and x 1-d vector\n",
        "  metric - is callable function 2 arguments\n",
        "  metric params for metric function\n",
        "  \"\"\"\n",
        "  distances = np.array([metric(x, X[idx]) for idx in range(X.shape[0])])\n",
        "  indeces = distances.argsort()[: k]\n",
        "  return distances[indeces], indeces"
      ],
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxjZVtF5aW6y"
      },
      "source": [
        "## 4. Применение модели\n",
        "<b>4.1. (2 балла)</b>\n",
        "\n",
        "Выгрузите датасет `ratings_small.csv`: https://www.kaggle.com/rounakbanik/the-movies-dataset#ratings_small.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr7-3CJhaW6z"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 505,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkSPOGQtdLLO"
      },
      "source": [
        "import pandas as pd\n",
        "file_path = \"/content/drive/MyDrive/Colab_Notebooks/recomendation_system/ratings_small.csv\"\n",
        "df_ratings = pd.read_csv(file_path)"
      ],
      "execution_count": 506,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NIYW8rOOnbR",
        "outputId": "3e8caccb-1afb-4e87-f1f9-72db38fc19d6"
      },
      "source": [
        "print(\"shape of data: {}\".format(df_ratings.shape))\n",
        "shape_begin = df_ratings.shape"
      ],
      "execution_count": 507,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of data: (100004, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su9OE6GTfSDE",
        "outputId": "2d0ff203-17b1-4966-b7e7-e71f6bf7fd88"
      },
      "source": [
        "df_ratings.columns"
      ],
      "execution_count": 508,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 508
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DQYt0qvg3t9",
        "outputId": "4b8547c9-969d-436d-a8d9-c28dcec23236"
      },
      "source": [
        "df_ratings.rating.value_counts()"
      ],
      "execution_count": 509,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0    28750\n",
              "3.0    20064\n",
              "5.0    15095\n",
              "3.5    10538\n",
              "4.5     7723\n",
              "2.0     7271\n",
              "2.5     4449\n",
              "1.0     3326\n",
              "1.5     1687\n",
              "0.5     1101\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 509
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiOA04ogaW6z",
        "outputId": "5fd3e09e-c5c2-415e-b20c-24c600566de6"
      },
      "source": [
        "df_ratings.userId.min(), df_ratings.userId.max(), len(df_ratings.userId.unique())"
      ],
      "execution_count": 510,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 671, 671)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 510
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTLLvJyqaW60",
        "outputId": "b973811e-c20f-4764-f66d-a603ffd92f8c"
      },
      "source": [
        "df_ratings.movieId.min(), df_ratings.movieId.max(), len(df_ratings.movieId.unique())"
      ],
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 163949, 9066)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 511
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb14sUcxaW60"
      },
      "source": [
        "Для простоты работы с данными, измените нумерацию пользователей и фильмов так, чтобы нумерация начиналась с 0 и шла непрерывно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oQJHYoUaW61"
      },
      "source": [
        "Удалим для наиболее активных пользователей 50 оценок. Для очень популярных пользователей брать 5 фильмов всего для  выбрасывания - маловато. Будет очень низкая оценка. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKFUh7B9aW62",
        "outputId": "1e352439-e310-4343-ac0d-c8614d44b8e5"
      },
      "source": [
        "num_films = 30\n",
        "active_users = df_ratings.userId.value_counts()[:10].index\n",
        "# -- Мы не убирали пока часть данных -- #\n",
        "if(df_ratings.shape[0] == shape_begin[0]):\n",
        "  test_data = pd.DataFrame([], columns=df_ratings.columns)\n",
        "  for user_id in active_users:\n",
        "      _, test = train_test_split(df_ratings[df_ratings.userId == user_id], \n",
        "                                test_size = num_films, \n",
        "                                random_state = 123)\n",
        "      test_data = test_data.append(test, ignore_index = True)\n",
        "      mask = ((df_ratings.userId == user_id) & (df_ratings.movieId.isin(test.movieId.values)))\n",
        "      # -- Убираем часть данных -- #\n",
        "      df_ratings = df_ratings[~mask]\n",
        "\n",
        "df_ratings.shape, test_data.shape"
      ],
      "execution_count": 512,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((99704, 4), (300, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 512
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NexgLyGLaW61"
      },
      "source": [
        "# -- by userId get continious id -- #\n",
        "userid_2_contuserid = {\n",
        "    usid : id \n",
        "    for id, usid in enumerate(df_ratings.userId.unique(), start = 0)\n",
        "    }\n",
        "# -- by continious id get userId -- #\n",
        "contuserid_2_userid = {idx: usid \n",
        "                       for usid, idx in userid_2_contuserid.items()\n",
        "                       }\n",
        "# -- by  movieid get continious id -- #                       \n",
        "movieid_2_contuserid = {\n",
        "    mid : id \n",
        "    for id, mid in enumerate(df_ratings.movieId.unique(), start = 0)\n",
        "    }\n",
        "# -- by continious id get movieid -- #                       \n",
        "\n",
        "contuserid_2_movieid = {idx: mid \n",
        "                       for mid, idx in movieid_2_contuserid.items()\n",
        "                       }                    \n",
        "\n",
        "# -- rename user ids -- #\n",
        "df_ratings.userId = df_ratings.userId.apply(lambda userid: userid_2_contuserid[userid])\n",
        "# -- rename movies ids -- #\n",
        "df_ratings.movieId = df_ratings.movieId.apply(lambda mid: movieid_2_contuserid[mid])\n",
        "\n",
        "# -- test data also rename -- #\n",
        "test_data.userId = test_data.userId.apply(lambda userid: userid_2_contuserid[userid])\n",
        "\n",
        "test_data.movieId = test_data.movieId.apply(lambda mid: movieid_2_contuserid.get(mid, -1))"
      ],
      "execution_count": 517,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkNNopR6aW61",
        "outputId": "eb8b6608-77a5-4e5b-ab0e-516fde791b04"
      },
      "source": [
        "df_ratings.userId.min(), df_ratings.userId.max(), len(df_ratings.userId.unique())"
      ],
      "execution_count": 518,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 670, 671)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 518
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ2rb-65aW61",
        "outputId": "eb1d1851-4f96-49e3-ff38-907f43133df4"
      },
      "source": [
        "df_ratings.movieId.min(), df_ratings.movieId.max(), len(df_ratings.movieId.unique())"
      ],
      "execution_count": 519,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 9038, 9039)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 519
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy_p1HjYoW_M"
      },
      "source": [
        "Хотелось бы для каждого пользователя посмотреть количество общих фильмов со всеми другими пользователями. Или отношение количества общих фильмов для каждой пары пользователей p, q к количеству объединенных фильмов пары p,q - |I(p) /\\ I(q)| / |I(p) \\/ I(q)|. Такое отношение посмотреть. Это может в некотором примитивном приближении показать насколько полтзователи в целом смотрят одинаковые фильмы именно в этом данном dataset.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV158sMGuZE9"
      },
      "source": [
        "**Ниже просто экспериментирую с самым первым что приходит на ум. Чтобы было что сравнить с предложенным подходом в классе UserBased system.** Суть в том, что давайте выкинем из данных для каждого пользователя по 50 филмов, чтобы вероятность выдать просмотренный, но удалённый фильм из данных был выше (всего уникальных фильмов ~10 000). Потом будем считать, сходство пользователей исключительно по sim(p, q) = |I(p) /\\ I(q)| / |I(p) / I(q)|. И по этому показателю выделять ближайших объектов.И рекомендовать фильмы по той же схеме, как и в UserBasedSystem. Как окажется, что алгоритм вообще говоря редко будет выдавать какие-то фильмы, которые мы выкинули выше! Поэтому данный подход достаточно плохой, хуже чем UserBasedSystem. Конечно, там ещё можно по подбирать оптимальным образом количество схожих пользователей, но лучшге от этого не особо станет. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aIagW-AeB7R",
        "outputId": "ddc11138-0efd-46c5-e81d-e68ea8c4d30c"
      },
      "source": [
        "# -- mask -- #\n",
        "\n",
        "matrix_masked = np.zeros((df_ratings.userId.unique().shape[0], \n",
        "                          df_ratings.movieId.unique().shape[0]), \n",
        "                          dtype = np.int16)\n",
        "\n",
        "unique_users = df_ratings.userId.unique()\n",
        "print(\"matrix_masked shape: {}\".format(matrix_masked.shape))\n",
        "group_users = df_ratings.groupby(by = 'userId')\n",
        "for uidx in unique_users:\n",
        "  df_uidx = group_users.get_group(uidx)\n",
        "  mask_uidxfilms = np.zeros((matrix_masked.shape[1], ), np.int16)\n",
        "  mask_uidxfilms[df_uidx['movieId'].values] = 1\n",
        "  matrix_masked[uidx, :] = mask_uidxfilms\n",
        "\n",
        "# -- created -- #\n",
        "common_films = matrix_masked @ matrix_masked.T\n",
        "assert(common_films.shape == (unique_users.shape[0], \n",
        "                              unique_users.shape[0]))\n",
        "common_films"
      ],
      "execution_count": 520,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "matrix_masked shape: (671, 9039)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 20,   0,   0, ...,   1,   0,   1],\n",
              "       [  0,  76,   8, ...,   2,   8,   9],\n",
              "       [  0,   8,  51, ...,   3,   5,  11],\n",
              "       ...,\n",
              "       [  1,   2,   3, ...,  37,   1,   4],\n",
              "       [  0,   8,   5, ...,   1,  31,  13],\n",
              "       [  1,   9,  11, ...,   4,  13, 115]], dtype=int16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 520
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onsm4K6uJ27a",
        "outputId": "e7e4ef2a-a15b-4c40-fbc4-052b236a0d1e"
      },
      "source": [
        "import numpy.ma as ma\n",
        "common_films_pd = pd.DataFrame([], \n",
        "                               columns = ['user1', \n",
        "                                          'user2', \n",
        "                                          'num_common_films'])\n",
        "\n",
        "# -- very slow -- #\n",
        "\"\"\"\n",
        "for idx in range(common_films.shape[0] - 1):\n",
        "  for jdx in range(idx + 1, common_films.shape[0], 1):  \n",
        "    dict_ = {'user1': idx, \n",
        "             'user2': jdx, \n",
        "             'num_common_films' : common_films[idx, jdx]}\n",
        "    common_films_pd = common_films_pd.append(dict_, \n",
        "                                             ignore_index=True)\n",
        "\"\"\"    \n",
        "mask = np.full((common_films.shape[0], common_films.shape[0]), \n",
        "               fill_value = 1, \n",
        "               dtype = np.uint8)\n",
        "\n",
        "maxes = []\n",
        "for uidx in range(common_films.shape[0] - 1):\n",
        "  mask[uidx, np.arange(uidx + 1, common_films.shape[0], 1)] = 0 \n",
        "  maxes.append(common_films[uidx, uidx+1: ].max())\n",
        "\n",
        "# -- Думал пригодиться -- #\n",
        "common_films_masked = ma.array(common_films, \n",
        "                               mask = mask)\n",
        "maxes = np.array(maxes)\n",
        "# -- Для каждого фильма есть много пересечений, то есть есть пользователи, которые смотрят достаточно много общего -- #\n",
        "# -- Чтобы подсчитать для каждой пары  |I(p) /\\ I(q)| / |I(p) / I(q)| создадим матрицу с знаменателями -- #\n",
        "# -- Хорошая функция apply_along_axis -- #\n",
        "\n",
        "times = -1\n",
        "def funct1(row, diag):\n",
        "  global times\n",
        "  times += 1\n",
        "  return row/(diag[times] + common_films.diagonal())\n",
        "\n",
        "num_users = common_films.shape[0]\n",
        "# -- Матрица |I(p) /\\ I(q)| / |I(p) / I(q)| значений размером num_users*num_users -- #\n",
        "weights_intersection = np.apply_along_axis(funct1, \n",
        "                                           1,\n",
        "                                           common_films, \n",
        "                                           common_films.diagonal())\n",
        "weights_intersection"
      ],
      "execution_count": 521,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5       , 0.        , 0.        , ..., 0.01754386, 0.        ,\n",
              "        0.00740741],\n",
              "       [0.        , 0.5       , 0.06299213, ..., 0.01769912, 0.07476636,\n",
              "        0.04712042],\n",
              "       [0.        , 0.06299213, 0.5       , ..., 0.03409091, 0.06097561,\n",
              "        0.06626506],\n",
              "       ...,\n",
              "       [0.01754386, 0.01769912, 0.03409091, ..., 0.5       , 0.01470588,\n",
              "        0.02631579],\n",
              "       [0.        , 0.07476636, 0.06097561, ..., 0.01470588, 0.5       ,\n",
              "        0.0890411 ],\n",
              "       [0.00740741, 0.04712042, 0.06626506, ..., 0.02631579, 0.0890411 ,\n",
              "        0.5       ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 521
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEkqEgYpYfL2",
        "outputId": "255b63b8-a7dc-467e-f5de-6e0d215f0138"
      },
      "source": [
        "# -- 0.5 значение говорит о том, что у пары пользователей есть 50 % общих просмотренных фильмов -- #\n",
        "\n",
        "# -- global variable weights_intersection -- #\n",
        "def get_knearest_users(user_id, k : int = 5):\n",
        "  \"\"\"\n",
        "  По построенной матрице, мы определяем с точки зрения данных \n",
        "  значений ближайших по общему пересечению объектов \n",
        "  returned - топ без самого себя конечно.\n",
        "  \"\"\"\n",
        "  return weights_intersection[user_id, :].argsort()[::-1][1: k + 1]\n",
        "\n",
        "def make_recomendations(df_train,\n",
        "                        user_id, \n",
        "                        top_films: int = 150, \n",
        "                        knearest : int = 50,\n",
        "                        import_rating = False):\n",
        "  # -- выделить похожих пользователей => (пользователи с большим относительным пересечением в просмотре фильмов) -- #\n",
        "  groupusers = get_knearest_users(user_id, knearest)\n",
        "  #group_users_df = df_train.groupby(by = ['userId'])\n",
        "  # -- see on each film and calculate pi -- #\n",
        "  maskusers = df_train.userId.apply(lambda userid: userid in set(groupusers))\n",
        "  P = np.array([\n",
        "        len(df_train[(df_train.movieId == filmid) & maskusers].userId.unique()) / len(groupusers)\n",
        "        for filmid in df_train.movieId.unique() \n",
        "      ])\n",
        "  filmindeces = P.argsort()[::-1][: top_films]\n",
        "  return P[filmindeces], filmindeces\n",
        "\n",
        "\n",
        "user_id_test = test_data.sample().userId.values[0]\n",
        "print('userid: ', user_id_test)\n",
        "Ps, topfilms = make_recomendations(df_ratings, \n",
        "                    user_id_test)\n",
        "np.sort(topfilms)"
      ],
      "execution_count": 522,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "userid:  546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  19,   23,   24,   27,   29,   38,   40,   42,   49,   57,   58,\n",
              "         59,   64,   69,   72,   75,   79,   86,   87,   88,   89,   90,\n",
              "         91,   92,   99,  101,  102,  105,  106,  110,  111,  113,  118,\n",
              "        119,  121,  122,  139,  143,  146,  153,  157,  159,  161,  170,\n",
              "        171,  172,  173,  174,  177,  179,  180,  181,  182,  183,  184,\n",
              "        185,  187,  188,  189,  190,  191,  194,  195,  196,  197,  199,\n",
              "        201,  202,  204,  213,  214,  225,  227,  229,  256,  263,  264,\n",
              "        272,  278,  287,  289,  290,  297,  298,  300,  324,  326,  327,\n",
              "        328,  329,  330,  332,  334,  335,  339,  341,  343,  358,  385,\n",
              "        389,  402,  403,  412,  417,  418,  432,  434,  435,  441,  445,\n",
              "        447,  457,  459,  468,  470,  480,  483,  505,  517,  519,  527,\n",
              "        551,  584,  690,  714,  720,  732,  733,  736,  738,  742,  767,\n",
              "        774,  776,  780,  785,  796,  801,  814,  824,  825,  874,  875,\n",
              "       1001, 1024, 1027, 1033, 1037, 1116, 2150])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 522
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkqxVHoqn59y",
        "outputId": "36540f0a-995d-4537-84ae-8f6561169498"
      },
      "source": [
        "Ps"
      ],
      "execution_count": 523,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96, 0.92, 0.92, 0.9 , 0.9 , 0.88, 0.88, 0.88, 0.86, 0.86, 0.84,\n",
              "       0.84, 0.84, 0.84, 0.84, 0.82, 0.82, 0.82, 0.82, 0.8 , 0.8 , 0.8 ,\n",
              "       0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.78, 0.78, 0.78, 0.78, 0.76, 0.76,\n",
              "       0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.74, 0.74, 0.74, 0.72, 0.72,\n",
              "       0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.7 , 0.7 , 0.7 , 0.7 ,\n",
              "       0.7 , 0.7 , 0.7 , 0.7 , 0.7 , 0.7 , 0.68, 0.68, 0.68, 0.68, 0.68,\n",
              "       0.68, 0.68, 0.68, 0.68, 0.68, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66,\n",
              "       0.66, 0.66, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64,\n",
              "       0.64, 0.64, 0.64, 0.64, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62,\n",
              "       0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.6 , 0.6 , 0.6 , 0.6 ,\n",
              "       0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.58, 0.58, 0.58, 0.58, 0.58, 0.58,\n",
              "       0.58, 0.58, 0.58, 0.58, 0.58, 0.58, 0.58, 0.58, 0.58, 0.58, 0.58,\n",
              "       0.58, 0.58, 0.58, 0.58, 0.58, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56,\n",
              "       0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 523
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI_hw0ajg4A_",
        "outputId": "891ba018-7c97-4ba7-8a50-6fdfcdf1511b"
      },
      "source": [
        "deletedmovies = test_data.groupby(by = 'userId').get_group(user_id_test).movieId\n",
        "deletedmovies"
      ],
      "execution_count": 524,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     5963\n",
              "1     4564\n",
              "2       -1\n",
              "3     5034\n",
              "4     3426\n",
              "5       -1\n",
              "6     4123\n",
              "7     8331\n",
              "8     5238\n",
              "9     8667\n",
              "10    1307\n",
              "11      -1\n",
              "12    3706\n",
              "13    4226\n",
              "14    6852\n",
              "15    6711\n",
              "16    4992\n",
              "17    1198\n",
              "18      -1\n",
              "19      -1\n",
              "20     628\n",
              "21    8507\n",
              "22    6021\n",
              "23    3096\n",
              "24    2017\n",
              "25    3833\n",
              "26      -1\n",
              "27    1268\n",
              "28    1960\n",
              "29     176\n",
              "Name: movieId, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 524
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbXT7FnLwEYK"
      },
      "source": [
        "**Пересечение в примитивном подходе**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-aU-RrdtXuR",
        "outputId": "668c1df7-e456-4f5b-bda4-6c964f1f1585"
      },
      "source": [
        "print(\"пересечение между рекомендованными и теми, что были удалены у пользователя: \", np.intersect1d(topfilms, deletedmovies))"
      ],
      "execution_count": 525,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "пересечение между рекомендованными и теми, что были удалены у пользователя:  []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "540wgU1vt_VV"
      },
      "source": [
        "Можно видеть достаточно малое пересечение! Оно и ясно, вообще говоря факт того, что пользователь посмотрел фильм не гарантирует его актуальность. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRq_q02AaW62"
      },
      "source": [
        "Преобразуем данные в таблицу `X`, с которой может работать `UserBasedRecommendation`, где $X_{ui} = r_{ui}$, если пользователь $u$ поставил оценку фильму $i$, и $X_{ui} = 0$, если пользователь $u$ не проставил оценку фильму $i$.\n",
        "\n",
        "Вам может пригодиться `csr_matrix`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZUxtCiiaW62",
        "outputId": "f70c46ea-da23-4243-d78e-f4b63fb98aaa"
      },
      "source": [
        "import scipy.sparse as scp\n",
        "def get_sparse(data,\n",
        "               colr :str,\n",
        "               colu :str,\n",
        "               colf :str\n",
        "               ):\n",
        "# -- colr, colu, colf -- #\n",
        "    return scp.coo_matrix(\n",
        "        (\n",
        "            data[colr],  \n",
        "            (data[colu], data[colf])\n",
        "        ), \n",
        "        shape=(len(userid_2_contuserid), len(movieid_2_contuserid))  # размеры матрицы рейтингов\n",
        "    ).tocsr()\n",
        "\n",
        "X_sp = get_sparse(df_ratings,\n",
        "                  colr = 'rating',\n",
        "                  colu = 'userId',\n",
        "                  colf = 'movieId')\n",
        "X_sp"
      ],
      "execution_count": 526,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<671x9039 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 99704 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 526
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBazrVTsazBa"
      },
      "source": [
        "Все численные эксперименты проводить ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE6Fu-FaaygV"
      },
      "source": [
        "from drive.MyDrive.Colab_Notebooks.recomendation_system.utils import euclidean_similarity2, Eweighted, PSweighted, apk, mapk"
      ],
      "execution_count": 527,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq4FAptU1D72",
        "outputId": "6c2b6c13-ac91-47f5-e707-e9742fcddb73"
      },
      "source": [
        "X_ex = np.copy(X_sp[1:].todense())\n",
        "x0 = np.copy(X_sp[0].todense()).reshape((X_sp.shape[1], ))\n",
        "\n",
        "metric_use = sim2metrics(Eweighted)\n",
        "dists, indeces = getkNearestNeighbors(X_ex, \n",
        "                                      x0, \n",
        "                                      metric = metric_use\n",
        "                                     )  \n",
        "\n",
        "dists, indeces"
      ],
      "execution_count": 528,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.95286195, 0.96035676, 0.96340362, 0.96949904, 0.97515074]),\n",
              " array([323, 308, 632,  33, 602]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 528
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s0dlzjdSZMp",
        "outputId": "31928145-1dcf-4e21-fd6b-98c8db4204ea"
      },
      "source": [
        "\n",
        "X_ex = np.copy(X_sp[1:].todense())\n",
        "x0 = np.copy(X_sp[0].todense()).reshape((X_sp.shape[1], ))\n",
        "\n",
        "metric_use = sim2metrics(PSweighted)\n",
        "dists, indeces = getkNearestNeighbors(X_ex, \n",
        "                                      x0, \n",
        "                                      metric = metric_use\n",
        "                                     )  \n",
        "\n",
        "dists, indeces.__len__()"
      ],
      "execution_count": 529,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.80878858, 0.86905229, 0.8941205 , 0.92003451, 0.92134547]), 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 529
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0J0lq_uHEGp",
        "outputId": "ef14b35d-e3d7-4c53-a652-3fcac4255f3a"
      },
      "source": [
        "class_ = UserBasedRecommendation(alpha = 0.2)\n",
        "class_.fit(X_sp.todense())\n",
        "\n",
        "dists, indeces = class_.find_closest_users(1, n_closest_users = 10)\n",
        "dists.shape, indeces.shape\n",
        "1-dists"
      ],
      "execution_count": 530,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape X matrix: (671, 9039)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.05714933, 0.0558315 , 0.0546354 , 0.0543141 , 0.04908214,\n",
              "       0.04879487, 0.04792717, 0.04714778, 0.04657866, 0.04451107])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 530
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuekCDgyXkUV"
      },
      "source": [
        "<b>2.2. (1 балла)</b>\n",
        "\n",
        "Приведите пример, для которого использование разных метрик будет давать разные рекомендации. Объясните свой пример."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqj6j5Y5XkUV"
      },
      "source": [
        "# -- Вообще говоря мне в целом странным кажется использовать данные меры сходства, особенно корреляцию пирсона -- #\n",
        "pass"
      ],
      "execution_count": 460,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSITUGaPXkUV"
      },
      "source": [
        "<b>Объяснение:</b> Для ясности пронумеруем товары с 0. Видно, что третьему пользователю так же как и второму больше понравился товар 1 и чуть меньше понравился товар 2, тогда как первому пользователю оба эти товары не сильно понравились, причем товар 1 ему понравился меньше, чем товар 2, то есть наблюдается обратная завизимость. Но все эти факторы никак не учитываются при использовании евклидовой метрики, поэтому в первом случае алгоритм посчитал, что первый и третий пользователь похожи только по тому, что они ставят оценки примерно в одном и том отрезке: {0, 1}, что является довольно странным предположением. А алгоритм, использующий коэффициент корреляции Пирсона учитывает эти факторы, поэтому находит третьему пользователю соседа со схожими интересами в виде второго пользователя. Отсюда получаем разные рекомендации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8adpd1rXkUW"
      },
      "source": [
        "## 3. Оценка качества\n",
        "<b>3.1. (1 балл)</b>\n",
        "\n",
        "Реализуйте Average Precision at k и Mean Average Precision at k. Шаблоны можете найти в `utils.py`.\n",
        "\\begin{align*}\n",
        "AP@K = \\frac{1}{m}\\sum_{k=1}^K P(k)*rel(k), \\\\\n",
        "MAP@K = \\frac{1}{|U|}\\sum_{u=1}^{|U|}(AP@K)_u\n",
        "\\end{align*}\n",
        "где $P(k)$ - Precision at k, $rel(k) = 1$, если рекомендация релевантна, иначе $rel(k) = 0$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqj3EtxlXkUZ"
      },
      "source": [
        "Для пользователей, у которых были удалены фильмы, найдите топ 100 фильмов, который должен посмотреть каждый из этих пользователей, используя `UserBasedRecommendation`. Не забудьте подобрать параметр alpha."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vi5gw6khre-"
      },
      "source": [
        "Ниже по UserBasedRecommendation - нахожу топ 100 фильмов и ниже пытаюсь оценить (считая в test_data, что фильм релевантный, если его оценка выше чем медианное значения для каждого отдельно взятого пользователя)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEohh8DtXkUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46dece5f-e779-4572-992c-c339c3cca7a3"
      },
      "source": [
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "# -- Что значит подобрать alpha? (по кроссвалидации как гиперпарамметр) -- #\n",
        "recomendclass = UserBasedRecommendation(metric = 'pearson',\n",
        "                                        n_recommendations = 100, \n",
        "                                        alpha = 0.095,\n",
        "                                        verbose = 1)\n",
        "\n",
        "# -- fit -- #\n",
        "recomendclass.fit(X_sp.todense())\n",
        "# -- Для наиболее активных пользователей топ 10 мы убрали по 5 случайных мувиков, которые он посмотрел -- #\n",
        "group_test = test_data.groupby(by = 'userId')\n",
        "topfilms = {}\n",
        "user_2_num_relevants_test = {}\n",
        "user_2_relevant_films = {}\n",
        "user_2_non_relevant_films = {}\n",
        "\n",
        "for it, us_idx in enumerate(test_data.userId.unique(), start = 1):\n",
        "  filmidxs = recomendclass.make_recommendation(us_idx,\n",
        "                                               n_recommendations = 100)\n",
        "  topfilms[us_idx] = filmidxs\n",
        "  assert(filmidxs.shape[0] == np.unique(filmidxs).shape[0])\n",
        "  print('userId: {} num of ratings: {}'.format(us_idx, \n",
        "                                               df_ratings[df_ratings.userId == us_idx].shape[0]))\n",
        "  # -- количество оценок в тестовой части данных -- #\n",
        "  #stars_idx = df_R.loc[us_idx, (df_R.loc[us_idx, :].notna())]\n",
        "  # -- Мы можем подсчитать для каждого пользователя median оценку и считать всё выше релевантным все ниже нерелевантным -- #\n",
        "  median_idx = df_ratings[df_ratings.userId == us_idx].rating.median()\n",
        "  print('idx: {} median: {}'.format(us_idx, median_idx))\n",
        "  # -- Воспользуемся рассчитанной медианной для расчёта количества релевантных пользователей -- #\n",
        "  user_2_num_relevants_test[us_idx] = (group_test.get_group(us_idx).rating >= median_idx).sum()\n",
        "  # -- calculate relevant users -- #\n",
        "  df_user_test = group_test.get_group(us_idx)\n",
        "  user_2_relevant_films[us_idx] = df_user_test[df_user_test.rating >= median_idx].movieId.values\n",
        "  # -- calculate non relevant users -- #\n",
        "  user_2_non_relevant_films[us_idx] = df_user_test[~(df_user_test.rating >= median_idx)].movieId.values\n",
        "\n"
      ],
      "execution_count": 531,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape X matrix: (671, 9039)\n",
            "userID: 546 number of neighbors: 32\n",
            "p sizes: 9039\n",
            "userId: 546 num of ratings: 2361\n",
            "idx: 546 median: 3.5\n",
            "userID: 563 number of neighbors: 49\n",
            "p sizes: 9039\n",
            "userId: 563 num of ratings: 1838\n",
            "idx: 563 median: 4.0\n",
            "userID: 623 number of neighbors: 50\n",
            "p sizes: 9039\n",
            "userId: 623 num of ratings: 1705\n",
            "idx: 623 median: 3.0\n",
            "userID: 14 number of neighbors: 82\n",
            "p sizes: 9039\n",
            "userId: 14 num of ratings: 1670\n",
            "idx: 14 median: 3.0\n",
            "userID: 72 number of neighbors: 84\n",
            "p sizes: 9039\n",
            "userId: 72 num of ratings: 1580\n",
            "idx: 72 median: 3.5\n",
            "userID: 451 number of neighbors: 74\n",
            "p sizes: 9039\n",
            "userId: 451 num of ratings: 1310\n",
            "idx: 451 median: 3.0\n",
            "userID: 467 number of neighbors: 94\n",
            "p sizes: 9039\n",
            "userId: 467 num of ratings: 1261\n",
            "idx: 467 median: 3.0\n",
            "userID: 379 number of neighbors: 84\n",
            "p sizes: 9039\n",
            "userId: 379 num of ratings: 1033\n",
            "idx: 379 median: 3.5\n",
            "userID: 310 number of neighbors: 76\n",
            "p sizes: 9039\n",
            "userId: 310 num of ratings: 989\n",
            "idx: 310 median: 3.0\n",
            "userID: 29 number of neighbors: 88\n",
            "p sizes: 9039\n",
            "userId: 29 num of ratings: 981\n",
            "idx: 29 median: 4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK6P9T2iiI6O"
      },
      "source": [
        "**Ниже словарь - каждому уникальному индексу пользователя ставиться в соответствие запись: (число релевантных фильмов, которые нашёл алгоритм/ числу релевантных алгоритмов в test_data)** Видно, что результаты выглядят печальненько... С другой стороны, ведь фильмов ~ 10000, может быть эти релевантные для себя фильмы пользователь ещё не посмотрел, и само выделение test_data происходит абсолютно случайно!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk0EXYNK9Ngz",
        "outputId": "c9a55c2a-887b-43a6-80d6-3c27ae172bc0"
      },
      "source": [
        "\"\"\" # -- У нас есть среди неизвестных оценок выбранных пользователей некоторые оценки,\n",
        "    которые мы разметили некоторым примитивным образом. В первом приближении лучше посмотреть будут ли\n",
        "    рекомендованные фильмы, которые были получены с помощью нашего алгоритма содержать данные фильмы! -- \"\"\"\n",
        "\n",
        "# -- Формально именно здесь мы смотрим на те ответы, которые есть в тесте, а не в обучающей выборке -- # \n",
        "user_2_top = {}\n",
        "user_2_num_in_top = {}\n",
        "sum_in_times = 0\n",
        "for uidx in test_data.userId.unique():\n",
        "  # -- uidx_d {index of film : position in top} -- #\n",
        "  uidx_d = {}\n",
        "  times_in = 0\n",
        "  for fidx in user_2_relevant_films[uidx]:\n",
        "    # -- либо найтись единственный / либо не найтись -- #\n",
        "    args = np.argwhere(topfilms[uidx] == fidx) \n",
        "    uidx_d[fidx] = -1 if( args.shape[0] == 0 ) else args[0][0] \n",
        "    times_in += 1 if uidx_d[fidx] != -1 else 0\n",
        "  user_2_top[uidx] = uidx_d\n",
        "  sum_in_times += times_in\n",
        "  user_2_num_in_top[uidx] = str(times_in) + '/' + str(user_2_relevant_films[uidx].shape[0])\n",
        "\n",
        "user_2_num_in_top, sum_in_times"
      ],
      "execution_count": 532,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({14: '0/10',\n",
              "  29: '1/23',\n",
              "  72: '0/21',\n",
              "  310: '0/17',\n",
              "  379: '0/20',\n",
              "  451: '2/23',\n",
              "  467: '0/17',\n",
              "  546: '0/18',\n",
              "  563: '1/17',\n",
              "  623: '0/18'},\n",
              " 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 532
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Rdbo6DpqAmJh",
        "outputId": "6c8a37ed-d36b-4092-d1e1-7ea9cadd7b0e"
      },
      "source": [
        "\"\"\"\n",
        " Стоит попробовать поперебирать коэффициент alpha \n",
        " чтобы лучше получать результаты, хотя бы чтобы ка можно меньше было -1 - \n",
        " которые говорят о том, что среди предсказанного топа элементов нет релевантных фильмов в том смысле, \n",
        " что оценка релевантного фильма для каждого пользователя определяется из соображений, что она больше \n",
        " медианного значения для фиксированного пользователя. \n",
        "\n",
        " Конечно это спорный момент, но мы хотим получить хоть что-то разумное в первом приближении прежде чем\n",
        " говорить о каких-то содержательных метриках качества apk and mapk, которые помимо всего этого \n",
        " учитывают порядок в котором идут топ эелементов! \n",
        "\"\"\""
      ],
      "execution_count": 533,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n Стоит попробовать поперебирать коэффициент alpha \\n чтобы лучше получать результаты, хотя бы чтобы ка можно меньше было -1 - \\n которые говорят о том, что среди предсказанного топа элементов нет релевантных фильмов в том смысле, \\n что оценка релевантного фильма для каждого пользователя определяется из соображений, что она больше \\n медианного значения для фиксированного пользователя. \\n\\n Конечно это спорный момент, но мы хотим получить хоть что-то разумное в первом приближении прежде чем\\n говорить о каких-то содержательных метриках качества apk and mapk, которые помимо всего этого \\n учитывают порядок в котором идут топ эелементов! \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 533
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFgG7Q3RQ8hX"
      },
      "source": [
        "По формуле: (Которая есть аналог ядерной регресии, где sim() - возьмём как cosine)\n",
        "\n",
        "$$\n",
        "  R^{'}_{i} = \\overline R_{a} + \\frac{\\sum_{j \\in KNN(i)} sum(i, j)*(R_{j, a} - \\overline R_{j} ))}{\\sum_{j \\in KNN(i)} sim(i, j)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2KGe2MmIDpL",
        "outputId": "79a71648-7817-4898-9cd9-65286aba6cd6"
      },
      "source": [
        "# -- Другие методы -- #\n",
        "\n",
        "def cosine_similarities(x, y):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  return np.dot(x, y)/(np.linalg.norm(x) * np.linalg.norm(y))\n",
        "\n",
        "# -- User_Items -- #\n",
        "X_dense = np.copy(X_sp.todense())\n",
        "# -- masked -- #\n",
        "mask = (X_dense == 0)\n",
        "X_masked = ma.array(X_dense, mask = mask)\n",
        "films_mean = X_masked.mean(axis = 0)\n",
        "users_mean = X_masked.mean(axis = 1)\n",
        "print(users_mean.shape, films_mean.shape)\n",
        "# -- сделаем предсказания только для тех данных, что мы выкинули -- #\n",
        "# -- Для разных функций sim() -- #\n",
        "preds = []\n",
        "for row in test_data.itertuples():\n",
        "  userid = getattr(row, 'userId')\n",
        "  filmid = getattr(row, 'movieId')\n",
        "  # -- calculate -- #\n",
        "  metric_ = sim2metrics(cosine_similarities)\n",
        "  # -- в сумме будет участвовать только ближайшие -- #\n",
        "  dists, indeces = getkNearestNeighbors(X_dense, \n",
        "                       X_dense[userid, :],\n",
        "                       metric = metric_, \n",
        "                       k = 50)\n",
        "  # -- dist(p, q) = 1 - sim(p, q) -- #\n",
        "  try:\n",
        "    sum_ = sum([\n",
        "            (X_dense[uidx, filmid] - users_mean[uidx]) * (1 - dists[idx])/sum(np.fabs(dists))\n",
        "            for idx, uidx in enumerate(indeces)\n",
        "           ])\n",
        "  except IndexError:\n",
        "    print(filmid, userid)\n",
        "  # -- write ans -- #\n",
        "  r = users_mean[userid] + sum_\n",
        "  preds.append((userid, filmid, r))\n",
        "\n",
        "preds = np.asarray(preds)\n",
        "# -- Обрезать что больше и меньше [0, 5]-- #\n",
        "preds[np.array([preds[idx][2] for idx in range(len(preds))]) < 0] = 0.5\n",
        "preds[np.array([preds[idx][2] for idx in range(len(preds))]) > 5.0] = 5.\n",
        "\n"
      ],
      "execution_count": 564,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(671,) (9039,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnVUikJSR86J"
      },
      "source": [
        "RMSE ответы на ratings на тестовых данных (можно поварьрировать количество ближайших):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc8bmFXWPm1S",
        "outputId": "71138032-8088-47a7-ce8b-0a0222eb02cc"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "preds_rating = preds[:, 2]\n",
        "print(\"rmse: {:.3f}\".format(np.sqrt(mean_squared_error(test_data.rating.values, preds_rating)/preds.shape[0])))"
      ],
      "execution_count": 565,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rmse: 0.118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCyj74-FSB_A"
      },
      "source": [
        "Чтобы подсчитать какие-нибудь метрики аналогичные APK, MAPK стоит определить, что называть релевантным фильмов и не релевантным. Выборка данных не позволяет точно ответить на данный вопрос. Я решил просто считать релевантым объект у которого оценка выше медианной для каждого объекта."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfTODy_8SBHs",
        "outputId": "17c77beb-bb86-469d-f7b7-695a8a87f5c5"
      },
      "source": [
        "# -- Попробуем с помощью данного метода определять релевантные -- #\n",
        "\n",
        "metric_ = sim2metrics(cosine_similarities)\n",
        "ans_all = {} \n",
        "for uidx in test_data.userId.unique()[:]:\n",
        "  print(uidx)\n",
        "  metric_ = sim2metrics(cosine_similarities)\n",
        "  dists, indeces = getkNearestNeighbors(X_dense, \n",
        "                                                X_dense[uidx, :],\n",
        "                                                metric = metric_, \n",
        "                                                k = 11)\n",
        "  # -- подсчитать ответы только на тех индексах фильма, которых ещё не видел текущий пользователь -- #\n",
        "  # -- 0.0 которые ещё не видел -- #\n",
        "  dists = dists[1:]\n",
        "  indeces = indeces[1:]\n",
        "\n",
        "  non_ans_films = np.arange(X_dense.shape[1])[(X_dense[uidx, :] == 0)]\n",
        "  print('for user: {} number not seen films : {}'.format(uidx, len(non_ans_films)))\n",
        "  r_dict = {}\n",
        "  for filmid in non_ans_films:\n",
        "    try:\n",
        "      sum_ = sum([\n",
        "              (X_dense[uid, filmid] - users_mean[uid]) * (1 - dists[idx])/sum(np.fabs(dists))\n",
        "              for idx, uid in enumerate(indeces)\n",
        "            ])\n",
        "    except IndexError:\n",
        "      print(filmid, uidx)\n",
        "\n",
        "    r = users_mean[userid] + sum_\n",
        "    # -- обрежем, если нужно -- #\n",
        "    r_dict[filmid] = np.clip(0, 5, r)  \n",
        "  # -- для каждого фильма выделяем top N -- #\n",
        "  N = 100\n",
        "  topfilms = np.array([ filmidx[0]\n",
        "             for filmidx in sorted(r_dict.items(), key = lambda x: x[1])[-N:]])\n",
        "\n",
        "  topfilms = topfilms[::-1]\n",
        "  ans_all[uidx] = topfilms"
      ],
      "execution_count": 593,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "546\n",
            "for user: 546 number not seen films : 6678\n",
            "563\n",
            "for user: 563 number not seen films : 7201\n",
            "623\n",
            "for user: 623 number not seen films : 7334\n",
            "14\n",
            "for user: 14 number not seen films : 7369\n",
            "72\n",
            "for user: 72 number not seen films : 7459\n",
            "451\n",
            "for user: 451 number not seen films : 7729\n",
            "467\n",
            "for user: 467 number not seen films : 7778\n",
            "379\n",
            "for user: 379 number not seen films : 8006\n",
            "310\n",
            "for user: 310 number not seen films : 8050\n",
            "29\n",
            "for user: 29 number not seen films : 8058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLVnx-VBXt-d",
        "outputId": "9b2e0b1d-693c-4abd-ab42-3c5e1e037cec"
      },
      "source": [
        "# -- Для каждого фильма можно подсчитать значения apk and another -- #\n",
        "apkall = {}\n",
        "K = [5, 10, 100]\n",
        "TD = test_data.groupby(by = 'userId')\n",
        "for uidx, preds in ans_all.items():\n",
        "  # test_data we have unknown #\n",
        "  dfidx = TD.get_group(uidx)\n",
        "  medianidx = dfidx.rating.median() \n",
        "  relevantmovies = dfidx[(dfidx.rating > median_idx)].movieId\n",
        "  print(\"for userid: {} number of relevant: {} and median rating: {}\".format(uidx, \n",
        "                                                       relevantmovies.shape[0],\n",
        "                                                       medianidx))\n",
        "  # -- apk for each -- #\n",
        "  apklist = []\n",
        "  for k in K:\n",
        "    apk_k = apk(relevantmovies, preds, k = k)\n",
        "    apklist.append(apk_k)\n",
        "\n",
        "  apkall[uidx] = apklist"
      ],
      "execution_count": 599,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for userid: 546 number of relevant: 6 and median rating: 3.5\n",
            "for userid: 563 number of relevant: 10 and median rating: 4.0\n",
            "for userid: 623 number of relevant: 1 and median rating: 3.0\n",
            "for userid: 14 number of relevant: 4 and median rating: 2.25\n",
            "for userid: 72 number of relevant: 5 and median rating: 4.0\n",
            "for userid: 451 number of relevant: 1 and median rating: 3.0\n",
            "for userid: 467 number of relevant: 2 and median rating: 3.0\n",
            "for userid: 379 number of relevant: 3 and median rating: 4.0\n",
            "for userid: 310 number of relevant: 1 and median rating: 3.0\n",
            "for userid: 29 number of relevant: 7 and median rating: 4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAoB1cTbdRmt"
      },
      "source": [
        "**Результаты apk, and mapk для подхода, реализованный выше по формуле.**\n",
        "В ключе сам уникальный индекс человека, а справа 3 числа (apk5, apk10, apk100)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8svDBkldQok",
        "outputId": "9de87b0e-2d5b-4787-fe07-2e7738d614b2"
      },
      "source": [
        "apkall"
      ],
      "execution_count": 600,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{14: [0.0, 0.0, 0.0],\n",
              " 29: [0.0, 0.0, 0.0],\n",
              " 72: [0.0, 0.0, 0.0],\n",
              " 310: [0.0, 0.0, 0.0],\n",
              " 379: [0.0, 0.0, 0.0],\n",
              " 451: [0.0, 0.0, 0.0],\n",
              " 467: [0.0, 0.0, 0.012195121951219513],\n",
              " 546: [0.0, 0.0, 0.0023148148148148147],\n",
              " 563: [0.0, 0.0, 0.002],\n",
              " 623: [0.0, 0.0, 0.0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 600
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WA2-nEveEZP"
      },
      "source": [
        "mapk: (mapk5, mapk10, mapk100)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEZAGiZreDwQ",
        "outputId": "8e2c5ad8-0ad2-496d-d97b-af7dedd8f2c0"
      },
      "source": [
        "mapk = np.array([apk for _, apk in apkall.items()]).sum(axis = 0)\n",
        "mapk"
      ],
      "execution_count": 601,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.01650994])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 601
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCwueSxbdzun"
      },
      "source": [
        "Данные метрики дают странные результаты. Значит по rmse, что я получил выше сложно что-то точное сказать. И сравнить с результами по метрикам apk, mapk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dqn3BmaXkUa"
      },
      "source": [
        "Как можно улучшить работу модели?\n",
        "\n",
        "<b>Уже много вариантов пытался сделать выше, в целом по поводу метрик mapk, apk не совсем понятно что они демонстрируют, так как данные очень разреженные и что назыввать релевантным и нерелевантным фильмом для конкретного человека тоже не ясно. А понимать это нужно, ибо метрики apk and mapk показывают насколько наше **ранжирование** - \"хорошо\", а вот это \"хорошо\" и не ясно что считать. Также меры сходства между пользователями ведут странно, если считать ближайших объектов на основе данных метрик сходства, то алгоритм может считать пары пользователей p, q - схожими, если у них всего 2-3 общих фильма, что достаточно странно!!! Я пытался ввести свою, взвешанную меру сходства с коэффициентом: |I(p) /\\ I(q)| / |I(p) / I(q)| = M(p, q)(мера Жаккара) - который как-то бы учитывал тот факт, что у \"похожих\" пользователей хорошо, чтобы и было относительно большое пересечение в просмотренных фильмах то есть пытался комбинировать pearson_similarities(p, q) * M(p, q) or euclidean_similarities(p, q) * M(p, q). Что тоже не дало чего-то сильно отличенного от других способов, но хотя бы с данным весом мне knearest выдавал пары пользователей у которых было ощутимое пересечение в просмотренных фильмах! \n",
        "\n",
        "Далее, пытался воспользоваться одним из базовых подходов GroupLens algorithm - это то, что я сделал последним. RMSE был не такой и большой пор-ка 0.11 на тестовых данных (выкинул для каждого пользователя по 30 фильмов, случайно без внимания на rating!) хотя это тоже может вызвать вопрос: \"А что считать хорошим RMSE?\" \n",
        "\n",
        "Можно было бы попробовать множество различных SVD методов, но уже мало времени. Тут необходимо учитывать специфику данных, от этого очень многие методы несостоятельны! </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "175KSqjngUdk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}